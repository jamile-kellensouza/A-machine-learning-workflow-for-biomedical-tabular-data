{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ki-fijUadUUlU8Wvzvgy8MTLVqJasj1g",
      "authorship_tag": "ABX9TyM2I9yOuQuPEtxqudxi1k4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamile-kellensouza/A-machine-learning-workflow-for-biomedical-tabular-data/blob/main/Agglomerative_HierarchicalClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr, pearsonr, pointbiserialr\n",
        "! pip install gower\n",
        "import gower\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "UxEtq7Zo-IK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/alzheimers_disease_data.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TCWrEhqwo1X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_fil = data.drop(columns=['PatientID', 'DoctorInCharge'])\n",
        "summary = data_fil.describe().T\n",
        "print(summary)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "got6YxvGohrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Hierarchical Grouping 1 - Eucliadine + average"
      ],
      "metadata": {
        "id": "_U_KY6ZC3sh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset - potencials features discriminatory\n",
        "features = ['MMSE', 'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'BehavioralProblems']\n",
        "df = data_fil[features].copy()\n",
        "df_f = data_fil[features + ['Diagnosis']].copy() # features + label - purity calculation\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_scaled = df.copy()\n",
        "df_scaled[['MMSE','FunctionalAssessment','ADL']] = scaler.fit_transform(df_scaled[['MMSE','FunctionalAssessment','ADL']])\n",
        "\n",
        "# Eucliadine distance\n",
        "\n",
        "euclid_dist = pdist(df_scaled, metric='euclidean')\n",
        "euclid_dist_matrix = squareform(euclid_dist)\n",
        "\n",
        "print(f\"Matriz de distância Euclidiana calculada com formato: {euclid_dist_matrix.shape}\")\n",
        "\n",
        "# ==============================================================\n",
        "# Hierarchical Grouping 1\n",
        "\n",
        "\n",
        "# Medium Linkage\n",
        "Z = linkage(euclid_dist, method='average')\n",
        "\n",
        "max_d = 2.7  # cutoff\n",
        "df['Cluster_Hierarquico_Eucli'] = fcluster(Z, max_d, criterion='distance')\n",
        "\n",
        "n_clusters = df['Cluster_Hierarquico_Eucli'].nunique()\n",
        "print(f\"Clusters formados: {n_clusters}\")\n",
        "display(df.head())\n",
        "\n",
        "# Dendrogram\n",
        "plt.figure(figsize=(7, 5))\n",
        "dendrogram(Z, labels=df.index, leaf_rotation=90, color_threshold=0,\n",
        "           above_threshold_color='k')\n",
        "plt.axhline(y=max_d, color='r', linestyle='solid', label=f'Corte = {max_d}')\n",
        "plt.title(\"[A] Dendrogram - Eucliadine distance\")\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "63ASXmUs2xLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intra - cluster distance\n",
        "intra_dist = []\n",
        "for cluster in range(1, n_clusters + 1):\n",
        "    indices = np.where(df['Cluster_Hierarquico_Eucli'] == cluster)[0]\n",
        "    if len(indices) > 1:\n",
        "        sub_dist = euclid_dist_matrix[np.ix_(indices, indices)]\n",
        "        mean_intra = (sub_dist.sum() - np.trace(sub_dist)) / (len(indices) * (len(indices) - 1))\n",
        "        intra_dist.append(mean_intra)\n",
        "    else:\n",
        "        intra_dist.append(0)\n",
        "\n",
        "print(f\"Intra-cluster distances per cluster: {intra_dist}\")\n",
        "print(f\"Average intra-cluster distances: {np.mean(intra_dist):.3f}\")\n",
        "\n",
        "# ==============================================================\n",
        "# inter - cluster distance\n",
        "\n",
        "inter_dist = []\n",
        "for c1 in range(1, n_clusters + 1):\n",
        "    for c2 in range(c1 + 1, n_clusters + 1):\n",
        "        idx1 = np.where(df['Cluster_Hierarquico_Eucli'] == c1)[0]\n",
        "        idx2 = np.where(df['Cluster_Hierarquico_Eucli'] == c2)[0]\n",
        "        sub_dist = euclid_dist_matrix[np.ix_(idx1, idx2)]\n",
        "        inter_dist.append(sub_dist.mean())\n",
        "\n",
        "print(f\"Inter-cluster distances between clusters: {inter_dist}\")\n",
        "print(f\"Average intra-cluster distances: {np.mean(inter_dist):.3f}\")\n",
        "\n",
        "# purity calculation\n",
        "df_f['Cluster_Hierarquico_Eucli'] = df['Cluster_Hierarquico_Eucli']\n",
        "if 'Diagnosis' in df_f.columns:\n",
        "    total = len(df_f)\n",
        "    purity_sum = 0\n",
        "    cluster_purity = {}\n",
        "\n",
        "    for cluster in range(1, n_clusters + 1):\n",
        "        indices = df_f['Cluster_Hierarquico_Eucli'] == cluster\n",
        "        true_labels = df_f.loc[indices, 'Diagnosis']\n",
        "\n",
        "        if len(true_labels) == 0:\n",
        "            continue\n",
        "\n",
        "        most_common = true_labels.value_counts().max()\n",
        "        purity_cluster = most_common / len(true_labels)\n",
        "\n",
        "        cluster_purity[cluster] = purity_cluster\n",
        "\n",
        "        purity_sum += most_common\n",
        "\n",
        "    purity_total = purity_sum / total\n",
        "\n",
        "    print(\"Individual purity per cluster:\")\n",
        "    for c, p in cluster_purity.items():\n",
        "        print(f\"  Cluster {c}: {p:.3f}\")\n",
        "\n",
        "    print(f\"\\nTotal purity: {purity_total:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No true label ('Diagnosis') was found for purity calculation.\")"
      ],
      "metadata": {
        "id": "B8DBJQdd21ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Hierarchical Grouping 2 - Gower + complete"
      ],
      "metadata": {
        "id": "CzrNDbMDzZ81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset - potencials features discriminatory\n",
        "features = ['MMSE', 'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'BehavioralProblems']\n",
        "df1 = data_fil[features].copy()\n",
        "df_f1 = data_fil[features + ['Diagnosis']].copy() # features + rótulo para calcular a pureza\n",
        "\n",
        "# Gower distance\n",
        "gower_dist = gower.gower_matrix(df1)\n",
        "\n",
        "print(f\" Matriz de distância de Gower calculada com formato: {gower_dist.shape}\")\n",
        "\n",
        "# ==============================================================\n",
        "# Hierarchical Grouping 2\n",
        "\n",
        "# complete linkage\n",
        "Z = linkage(gower_dist, method='complete')\n",
        "\n",
        "\n",
        "max_d = 17.5  # cutoff\n",
        "df1['Cluster_Hierarquico_gower'] = fcluster(Z, max_d, criterion='distance')\n",
        "\n",
        "n_clusters = df1['Cluster_Hierarquico_gower'].nunique()\n",
        "print(f\"Clusters formados: {n_clusters}\")\n",
        "display(df1.head())\n",
        "\n",
        "\n",
        "# Dendrogram\n",
        "plt.figure(figsize=(7, 5))\n",
        "dendrogram(Z, labels=df1.index, leaf_rotation=90,color_threshold=0,\n",
        "           above_threshold_color='k')\n",
        "plt.axhline(y=max_d, color='r', linestyle='solid', label=f'Corte = {max_d}')\n",
        "plt.title(\"[B] Dendrogram - Gower distance\")\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KFFnvBP_v22v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intra - cluster distance\n",
        "intra_dist = []\n",
        "for cluster in range(1, n_clusters+1):\n",
        "    indices = np.where(df1['Cluster_Hierarquico_gower'] == cluster)[0]\n",
        "    if len(indices) > 1:\n",
        "        sub_dist = gower_dist[np.ix_(indices, indices)]\n",
        "        mean_intra = (sub_dist.sum() - np.trace(sub_dist)) / (len(indices)*(len(indices)-1))\n",
        "        intra_dist.append(mean_intra)\n",
        "    else:\n",
        "        intra_dist.append(0)\n",
        "print(f\"Intra-cluster distance per cluster: {intra_dist}\")\n",
        "print(f\"Average intra-cluster distance: {np.mean(intra_dist):.3f}\")\n",
        "\n",
        "# ==============================================================\n",
        "# inter - cluster distance\n",
        "\n",
        "inter_dist = []\n",
        "for c1 in range(1, n_clusters+1):\n",
        "    for c2 in range(c1+1, n_clusters+1):\n",
        "        idx1 = np.where(df1['Cluster_Hierarquico_gower']==c1)[0]\n",
        "        idx2 = np.where(df1['Cluster_Hierarquico_gower']==c2)[0]\n",
        "        sub_dist = gower_dist[np.ix_(idx1, idx2)]\n",
        "        inter_dist.append(sub_dist.mean())\n",
        "print(f\"Inter-cluster distances between clusters: {inter_dist}\")\n",
        "print(f\"Average inter-cluster distance: {np.mean(inter_dist):.3f}\")\n",
        "\n",
        "# purity calculation\n",
        "df_f1['Cluster_Hierarquico_gower'] = df1['Cluster_Hierarquico_gower']\n",
        "if 'Diagnosis' in df_f1.columns:\n",
        "    total = len(df_f1)\n",
        "    purity_sum = 0\n",
        "    cluster_purity = {}\n",
        "\n",
        "    for cluster in range(1, n_clusters + 1):\n",
        "        indices = df_f1['Cluster_Hierarquico_gower'] == cluster\n",
        "        true_labels = df_f1.loc[indices, 'Diagnosis']\n",
        "\n",
        "        if len(true_labels) == 0:\n",
        "            continue\n",
        "\n",
        "        most_common = true_labels.value_counts().max()\n",
        "        purity_cluster = most_common / len(true_labels)\n",
        "\n",
        "        cluster_purity[cluster] = purity_cluster\n",
        "\n",
        "        purity_sum += most_common\n",
        "\n",
        "    purity_total = purity_sum / total\n",
        "\n",
        "\n",
        "    print(\"Individual purity per cluster\")\n",
        "    for c, p in cluster_purity.items():\n",
        "        print(f\"  Cluster {c}: {p:.3f}\")\n",
        "\n",
        "    print(f\"\\nTotal purity: {purity_total:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No true label ('Diagnosis') was found for purity calculation.\")\n"
      ],
      "metadata": {
        "id": "BDFC_HVayDko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Hierarchical Grouping 3 - Hamming - complete"
      ],
      "metadata": {
        "id": "pDYOchW34Qmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset - potencials features discriminatory\n",
        "features = ['MemoryComplaints', 'BehavioralProblems']\n",
        "df2 = data_fil[features].copy()\n",
        "df_f2 = data_fil[features + ['Diagnosis']].copy()\n",
        "\n",
        "# Ensure that binary data is an integer\n",
        "df2 = df2.astype(int)\n",
        "\n",
        "# ==============================\n",
        "# Hamming Distance\n",
        "\n",
        "dist_hamming = pdist(df2, metric='hamming')\n",
        "dist_square = squareform(dist_hamming)\n",
        "\n",
        "# ==============================================================\n",
        "# Hierarchical Grouping 3\n",
        "\n",
        "# Complete linkage\n",
        "\n",
        "Z = linkage(dist_hamming, method='complete')\n",
        "\n",
        "max_d = 0.8  # # cutoff\n",
        "df2['Cluster_Hierarquico_Hamm'] = fcluster(Z, max_d, criterion='distance')\n",
        "\n",
        "n_clusters = df2['Cluster_Hierarquico_Hamm'].nunique()\n",
        "print(f\"Clusters formados: {n_clusters}\")\n",
        "display(df2.head())\n",
        "\n",
        "# Dendrogram\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "dendrogram(Z, labels=df2.index, leaf_rotation=90,truncate_mode='lastp', p=1200,\n",
        "           color_threshold=0,above_threshold_color='k')\n",
        "plt.axhline(y=max_d, color='r', linestyle='solid', label=f'Corte = {max_d}')\n",
        "plt.title(\"[C] Dendrogram - Hamming distance\")\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwCnGj0I7RXe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intra-cluster distance\n",
        "intra_dist = []\n",
        "\n",
        "for cluster in range(1, n_clusters+1):\n",
        "    idx = np.where(df2['Cluster_Hierarquico_Hamm'] == cluster)[0]\n",
        "    if len(idx) > 1:\n",
        "        sub_dist = dist_square[np.ix_(idx, idx)]\n",
        "        mean_intra = np.mean(sub_dist[np.triu_indices(len(idx), k=1)])\n",
        "        intra_dist.append(mean_intra)\n",
        "    else:\n",
        "        intra_dist.append(np.nan)\n",
        "\n",
        "print(f\"Intra-cluster distance per cluster: {intra_dist}\")\n",
        "print(f\"Average intra-cluster distance: {np.nanmean(intra_dist):.3f}\")\n",
        "\n",
        "# Inter - cluster distance\n",
        "inter_dist = []\n",
        "\n",
        "for c1 in range(1, n_clusters+1):\n",
        "    for c2 in range(c1+1, n_clusters+1):\n",
        "        idx1 = np.where(df2['Cluster_Hierarquico_Hamm'] == c1)[0]\n",
        "        idx2 = np.where(df2['Cluster_Hierarquico_Hamm'] == c2)[0]\n",
        "        sub_dist = dist_square[np.ix_(idx1, idx2)]\n",
        "        inter_dist.append(sub_dist.mean())\n",
        "\n",
        "print(f\"Inter-cluster distances between clusters {inter_dist}\")\n",
        "print(f\"Average inter-cluster distance: {np.mean(inter_dist):.3f}\")\n",
        "\n",
        "# purity calculation\n",
        "df_f2['Cluster_Hierarquico_Hamm'] = df2['Cluster_Hierarquico_Hamm']\n",
        "\n",
        "if 'Diagnosis' in df_f2.columns:\n",
        "    total = len(df_f2)\n",
        "    purity_sum = 0\n",
        "    cluster_purity = {}\n",
        "\n",
        "    for cluster in range(1, n_clusters + 1):\n",
        "        indices = df_f2['Cluster_Hierarquico_Hamm'] == cluster\n",
        "        true_labels = df_f2.loc[indices, 'Diagnosis']\n",
        "\n",
        "        if len(true_labels) == 0:\n",
        "            continue\n",
        "\n",
        "        most_common = true_labels.value_counts().max()\n",
        "        purity_cluster = most_common / len(true_labels)\n",
        "\n",
        "        cluster_purity[cluster] = purity_cluster\n",
        "\n",
        "        purity_sum += most_common\n",
        "\n",
        "    purity_total = purity_sum / total\n",
        "\n",
        "\n",
        "    print(\"Individual purity per cluster\")\n",
        "    for c, p in cluster_purity.items():\n",
        "        print(f\" Cluster {c}: {p:.3f}\")\n",
        "\n",
        "    print(f\"\\nTotal purity: {purity_total:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No true label ('Diagnosis') was found for purity calculation.\")"
      ],
      "metadata": {
        "id": "AXN8wqjT7ngC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}